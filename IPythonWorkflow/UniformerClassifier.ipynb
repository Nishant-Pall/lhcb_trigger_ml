{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# be sure to import SkLearnSimpleUtils.ipynb before importing this file\n",
      "# In this notebook a metaclassifier is introduced\n",
      "# Its aim is to make from some basic classifier (no matter which) some classifier \n",
      "# with uniform precision along some variable (usually mass)\n",
      "\n",
      "# How does it work: it splits the mass space into bins, \n",
      "# for each bin a separate basic classifier is learnt, \n",
      "# when getting prediction_probas, the predictions of basic classifier \n",
      "# are altered by some correcting monotonic function"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "import numpy\n",
      "def GetTrainTestDataForBin(binsData, binIndex, mode = 'outer'):\n",
      "    \"\"\"\n",
      "    Mode = outer or innerNoSplit or innerSplit\n",
      "    Returns binFitX, binCorrX, binFitY, binCorrY\n",
      "    \"\"\"\n",
      "    binX = binsData[binIndex][1]\n",
      "    binY = binsData[binIndex][2]\n",
      "    binsNumber = len(binsData)\n",
      "    if mode == 'outer':\n",
      "        otherBins = binsData[:binIndex] + binsData[binIndex+1:]\n",
      "        binFitX = numpy.concatenate(tuple( [binData[1] for binData in otherBins] ))\n",
      "        binFitY = numpy.concatenate(tuple( [binData[2] for binData in otherBins] ))\n",
      "        binCorrX = binX\n",
      "        binCorrY = binY\n",
      "    elif mode == 'innerNoSplit':\n",
      "        binFitX = binCorrX = binX\n",
      "        binFitY = binCorrY = binY\n",
      "    elif mode == 'innerSplit':\n",
      "        binFitX, binCorrX, binFitY, binCorrY = \\\n",
      "            train_test_split(binX, binY, test_size = 0.5)\n",
      "    else:\n",
      "        throw('Wrong mode')\n",
      "    return binFitX, binCorrX, binFitY, binCorrY\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "class UniformerClassifier(BaseEstimator, ClassifierMixin):\n",
      "    \"\"\"The metaclassifier, which tries to make efficiency uniform on the mass\"\"\"\n",
      "    def __init__(self, baseClassifier, binsNumber = 10, splitOnTestAndTrain = True):\n",
      "        self.baseClassifier = baseClassifier\n",
      "        self.binsNumber = binsNumber\n",
      "        self.splitOnTestAndTrain = splitOnTestAndTrain\n",
      "    def fit(self, X, y, masses, drawPlots = False, mode = 'outer'):\n",
      "        if self.binsNumber == 1 and mode == 'outer':\n",
      "            throw('Cannot use outer mode with only one bin')\n",
      "        assert len(X) == len(y), \"Different size of arrays\"\n",
      "        assert len(X) == len(masses), \"Different size of arrays\"\n",
      "        # binning\n",
      "        self.binner_ = Binner(masses, self.binsNumber)\n",
      "        self.classifiers = []\n",
      "        self.lambdaUniformers = []\n",
      "        splittedBinsData = list(self.binner_.splitIntoBins(masses, X, y))\n",
      "        for binIndex in range(len(splittedBinsData)):\n",
      "            binClassifier = clone(self.baseClassifier)\n",
      "            \n",
      "            binFitX, binCorrX, binFitY, binCorrY = \\\n",
      "                GetTrainTestDataForBin(splittedBinsData, binIndex, mode)\n",
      "            # binFitX, binFitY are used to fit base classifier\n",
      "            # binCorrX, binCorrY are used to obtain uniformer function\n",
      "            \n",
      "            binClassifier.fit(binFitX, binFitY)\n",
      "            self.classifiers.append(binClassifier)\n",
      "            predictions = binClassifier.predict_proba(binCorrX)[:,1]\n",
      "            #self.testPredictions = predictions\n",
      "            lmb = CorrectionFunction(binCorrY, predictions, 200)\n",
      "            self.lambdaUniformers.append(lmb)\n",
      "            if drawPlots:\n",
      "                # Draw plots of efficien\u0441y vs cut\n",
      "                plotFunction(lmb)\n",
      "                effData = efficiencyPlotData(binCorrY, predictions)\n",
      "                plot(effData[0], effData[1])\n",
      "                pylab.show()\n",
      "        return self\n",
      "    def predict(self, X, mass):\n",
      "        assert len(mass) == len(X), 'Different size of arrays'\n",
      "        result = np.zeros(len(X))\n",
      "        \n",
      "        binsIndices = self.binner_.getBins(mass)\n",
      "        for i in range(len(mass)):\n",
      "            binNumber = binsIndices[i]\n",
      "            result[i] = self.classifiers[binNumber].predict(X.irow(i))\n",
      "        return result\n",
      "    def predict_proba(self, X, mass):\n",
      "        # use binner for correcting predictions\n",
      "        # \u0442\u043e\u0440\u043c\u043e\u0437\u043a\u043e\u0434\n",
      "        assert len(mass) == len(X), 'Different size of arrays'\n",
      "        predicts = np.ndarray((len(mass),2))\n",
      "        binsIndices = self.binner_.getBins(mass)\n",
      "        for i in range(len(mass)):\n",
      "            binNumber = binsIndices[i]\n",
      "            p = self.classifiers[binNumber].predict_proba(X.irow(i))[0,1]\n",
      "            lmb = self.lambdaUniformers[binNumber]\n",
      "            pNew = 1 - lmb(p)\n",
      "            #print p, pNew\n",
      "            #if not useMass:\n",
      "            #    pNew = p\n",
      "            predicts[i, 0] = 1 - pNew\n",
      "            predicts[i, 1] = pNew\n",
      "        return predicts\n",
      "            \n",
      "    def get_params(self, deep = False):\n",
      "        return {\"baseClassifier\": self.baseClassifier, \n",
      "                \"binsNumber\": self.binsNumber,\n",
      "                \"splitOnTestAndTrain\": self.splitOnTestAndTrain}\n",
      "    def set_params(self, **parameters):\n",
      "        for parameter, value in parameters.items():\n",
      "            self.setattr(parameter, value)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.lda import LDA\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.metrics import f1_score\n",
      "import pandas\n",
      "from numpy import random\n",
      "\n",
      "def generateSampleData(length, columns = 3):\n",
      "    # generating random data for classification\n",
      "    df = pandas.DataFrame(np.random.rand(length, columns))\n",
      "    cols = df.columns\n",
      "    coeffSum = 0\n",
      "    answers = np.zeros(length) \n",
      "    for col in cols:\n",
      "        coeff = random.uniform()\n",
      "        coeffSum += coeff \n",
      "        answers += df[col] * coeff\n",
      "        \n",
      "    return df, answers >= 0.5 * coeffSum\n",
      "\n",
      "def testUniformerClassifier():\n",
      "    unif = UniformerClassifier(LDA())\n",
      "    unif2 = clone(unif)\n",
      "    \n",
      "    data, answers = generateSampleData(1000, 5)\n",
      "    trainX, testX, trainY, testY = train_test_split(data, answers, train_size = 0.5)\n",
      "    testX = pandas.DataFrame(testX)\n",
      "    trainX = pandas.DataFrame(trainX)\n",
      "    \n",
      "    unif = UniformerClassifier(GaussianNB(), 1)\n",
      "    unif.fit(trainX, trainY, trainX[0], mode = 'innerNoSplit')\n",
      "    predictions = unif.predict(testX, testX[0])\n",
      "    prediction_probas = unif.predict_proba(testX, testX[0])\n",
      "\n",
      "    if f1_score(predictions, testY) < 0.75:\n",
      "        print 'predictions are awful, f1 = ' + str(f1_score(predictions, testY))\n",
      "    print 'uniformer classifier is ok'\n",
      "    \n",
      "\n",
      "    \n",
      "    \n",
      "testUniformerClassifier()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'UniformerClassifier' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-0f4a1c760b7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtestUniformerClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-3-0f4a1c760b7e>\u001b[0m in \u001b[0;36mtestUniformerClassifier\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtestUniformerClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0munif\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUniformerClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0munif2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munif\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: global name 'UniformerClassifier' is not defined"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}